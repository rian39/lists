# Probabilities in the data analytic conversion of social order

# A. Introduction  includes a,b,c from above

This paper is a philosophical reconstruction [@Dewey_2017] of an online grocery ordering system undergoing an upgrade. The reconstruction is empirical in certain respects. It departs from an ethnographic moment: being a member of the audience at an industry/academic conference where a data scientist was describing how recommendations were created for online grocery orders. Starting from this highly mediated and fragmentary encounter with a recommender system and one of its designers, the paper explores the problem the system addresses.  It draws on anthropological and sociological research concerning shopping and list-making to situate the recommender system amongst the social ordering practices of shopping and shopping lists. It makes use of archaeological approaches, in the sense developed by Michel Foucault [@Foucault_1972] in order to identify and map important functional statements and practices configuring the knowledge and order generated by such systems over time. It conducts several code-based experiments in order to reconstruct, using widely available code resources resources such as API (Application Programmer Interfaces) and software libraries for machine learning, some prototypical elements of the system in question.  In doing this, it draws  on the philosophy of science and media theory to frame an engagement with data, algorithms and recommendations around probabilities and their worldly enactments.

Like some recent work in science and technology studies,  anthropology and media studies [@Marres_2017; @Marcus_2014; @Bogost_2012], through this combination of approaches,  the paper allows its own reconstruction to be provisionally shaped by an experiential encounter with the object it describes. At times, this mode of empirical philosophical engagement with its objects may well seem overly concerned with the technical minutiae of the grocery ordering system, and lacking in  sociological rigour or empirical evidence. With some forbearance on the part of readers, however, the main philosophical argument of the paper should resonate sociologically. It concerns social order, or the consistency and regularity of relating and acting amid a world in where probabilities and calculations based on probabilities play a more pervasive role.

The main argument of the paper concerns how  probability operates in Big Data situations. While calculations of probability have  long-standing importance in many settings (insurance, medicine, experimental and field sciences, operations research, risk analysis, engineering design, public health,  economic modelling, etc.), probabilities have taken on a much thicker situational texture. In recent research and opinion on  data practice, personalization has been seen as the linchpin of predictive modelling. The reconstruction of the recommender system suggests a different way of seeing these transformations.   Operational probabilities differ from epistemic probabilities in their position in the world, as part of infrastructures, transactions, and event-structures. Taking their complex siting into account, and accepting their _physical_ reality, we might come to understand the world operative probabilities belong to as what the philosopher of science Karl Popper understood as a 'world of propensities, as an unfolding process of realizing possibilities and of unfolding new possibilities' [@Popper_1990,19]. Given this understanding of operational probability, our understanding of what is enacted in contemporary data analytics, especially in association with platforms [@Gillespie_2010] where the operationality of probabilities are heightened,  might shift. 

The broad implication of the argument concerns how we think about social order or regularities amidst change or transformation. Proponents and critics of Big Data present the advent of large volumes of data and analytical techniques (machine learning in particular) as transforming for better or worse organisations, institutions, economic processes and social life. Personalization has been a pivotal element, they argue, of this transformation.  I suggest too that a transformation or conversion event is occurring, but one which might also, even in the midst of much ongoing personalization,  open up the possibility of experiencing the world differently, and conceiving of social ordering processes somewhat afresh. Even if the argument is centred on shopping, the analysis of how a world of propensities continuously and unevenly converts into realizations applies across the board, from the most physical to the most ideal or abstract settings. The average everydayness of the example here -- grocery shopping -- allows some first hand engagement with the messiness, the entanglements, and potentials of this conversion event in ways that other interesting settings -- particle physics for instance -- do not.

# B. Patel section + opening description

At one of the many industry-meets-academia events occurring in increasingly data science-oriented higher education institutions in the UK, speakers from industry, government and commerce described their work with predictive models.[^11.1] Shreena Patel, a PhD graduate in statistics and operations research,  works as a data scientist for DunnHumby, a well-known [ customer science company ](https://www.dunnhumby.com/) [@dunnhumby_2017].  Her work at DunnHumby focuses on online grocery shopping at the supermarket chain Tesco.  Speaking to an audience of statisticians and operations researchers, Patel focused on the development and operation of predictive models underlying  shopping list recommendations. Her presentation was filled with graphs, numbers, and tables concerning ongoing development of the 'Have you forgotten?' recommender system. 

[^11.1]: More than 100  Data Science Institutes have been set up in North America, Europe and UK since around 2012. The traffic between higher education and data analytics in industry is intense and flows in several forms: people funding, research findings, software and technical devices (code) and training. 

Against the background of the sheer number of commodities and their distribution of prices,  Patel's presentation presents two opportunities. First, by recounting, contextualising and commenting on the main steps in making the 'Have your forgotten?' list, we might follow some of the predictive sense-making done by data scientists and customer analytics teams working with transactional data in a typical commercial setting. Patel mentioned many of these steps only fleetingly in the presentation, for they are largely taken for granted as part of predictive analytic practice. Second, Patel focused on the renovation and updating of long-standing data-mining practice via a much more explicitly 'big data' and 'machine learning' oriented implementation. Her presentation concerns what we might term, for reasons that will gradually emerge, a 'conversion event' in which a long-standing recommender system was replaced by a new, explicitly 'big data'-style system concerned with 'personally relevant' recommendations.   What stands out from the presentation is the normality of the recommender system: it is part of a long-standing and ongoing transformation or conversion of grocery shopping. From a sociological standpoint, the interest lies less in specific technical innovations and more on how the ordering work done by recommender systems relates to problems of social order more generally. 

Online grocery shopping at [Tesco](https://www.tesco.com/groceries/?icid=dchp_groceriesshopgroceries), the largest supermarket chain in the UK, includes recommendations for further grocery purchases under the title of 'Have you forgotten?'. When Tesco customers shop for groceries online, a list of five recommendations appear at the checkout stage. The recommendations are the product of a recommender system, an important category of operational device in big data (see for instance [@Striphas_2015] for analysis of Netflix recommendation; [@Morris_2015]  or [@Seaver_2015] for an account of music recommendations).  The question 'have you forgotten?' is followed by a list of some  grocery items that could have been or are usually on a shopping list. The title of the suggestions is a bit misleading: the recommender system, as we will see, is not concerned with forgetting, with the many slips and oversights associated to which shopping is prone,  but rather with items that customers had not selected perhaps because they had never thought of buying them in the first place.

[TBA: THIS PARA could be moved down] The shelves of large contemporary supermarket are the endpoint of global logistic supply chains, in all their logistical, value-transforming and brand-mediated hypercomplexity (see [@Neilson_2012; @Tsing_2009]).  Groceries imply a planetary geography of agriculture, industry, transport, communication and financialisation animated by flows of labour and capital. Encounters between this hyper-complex commodity-geography and people, even in the familiar confines of a supermarket, are no simple matter, either for shoppers or for supermarket operators such as Tesco.

# C. Shopping  lists and  a theory of social ordering 

The anthropologist  Daniel Miller has argued [@Miller_2012] that  shopping takes place as a negotiation of discrepancies between normative and actual social order (for instance, between ideals of health and commitments to thrift). What Miller suggests here is that ... [TBA]  It can also be seen  as a sacrificial ritual that re-instates social order in various ways. 

From an ethnomethodological standpoint, shopping lists provide important clues to how local social order is constituted, maintained, and repaired. Social ordering is done in shopping, and the shopping list as an inscriptive device stabilises certain forms of ordering at the expense of other possible orderings.  

The shopping list, whether written on the back of an envelope, or saved as a list in an online grocery shopping system, lies at the intersection of logistical flows, infrastructural orderings, and  lively negotiations around actual and normative social orders.  Shopping lists, therefore  are intersectional ordering devices that encapsulates a universe of possible references, and a teeming multitude of propensities with an actual local order (in both senses of that term: an ordering and an imperative). As people shop, either by  trawling along aisles packed with thousands of products, or scrolling down screens or searching for particular brands amidst search results, lists inscribe some kind of order that filters or reduces the excessive propensities, claims, dazzle and distraction of commodities to the practicalities of domestic economy.

Hand-written shopping lists undoubtedly have ongoing importance and display interestingly mixed ordering practices (see the montage of handwritten shopping lists at [Grocery List](http://www.grocerylist.org)). But online shopping lists take shape at the intersection of web and internet infrastructures, supply chain logistics, individualised practices and *habitus,* and increasingly, the predictive operations of  recommender systems. Just as the aisles and shelves of a supermarket present a densely-woven semiotics of objects competing for visual attention by offering distinctions of taste, thrift, expedience, novelty, indulgence, health and increasingly, online shopping recommender systems generate lists that seek to align people to commodities that they otherwise might have little relation to (see [@Turow_2015] for an overview).  

If, as the social anthropologist Jack Goody argues, lists are historically primary as forms of writing in urbanizing cultures [@Goody_1986], and if list-making and its later variants (e.g. tables) precede discursive and narrative writing practices, then we might expect lists to function as powerful social ordering devices. More recent sociological work on lists (see [@deGoede_2016] for an overview) explore the social and political potency of lists as ordering devices. As literary scholars suggest (see [@Mainberger_2003]), even if lists have often been de-valued as literary forms, list-making commonly appears in literary form whenever writing seeks to address, name, group or evoke totality, profusion, excess or abundance. From both  anthropological and literary perspectives, shopping lists have excellent reasons to exist: they are deeply rooted in organisational life and infrastructures. Lists weave together people, infrastructures, things, and places.[^1.456]    

[^1.456]: While lists intersect strongly with other meaning and sense-making practices in everyday life and popular culture, they can be refractory to discourse  and textual analysis methods built around models of language or speech, with its rules of syntax and grammar. On the one hand, lists are highly associative. They can be interpreted or decoded semiotically, although they exhibit  variations in textuality -- how they are written and read -- that thwart semiotic readings. On the other hand, as operational inscriptions, they can be treated ethnomethodologically, as the production of social order in a given setting. We might, in the light of their mutability, permeability and embedding in social order,  approach lists from various theoretical angles -- as asignifying semiotics as Maurizio Lazzarato calls it in his _Signs and Machines_ [@Lazzarato_2014] or as elements in 'a new order of spatio-temporal continuity for forms of economic, political and cultural life' as Celia Lury puts it in her account of topological turn [@Lury_2012].

Finally, and more formally, we might also consider some of the formal properties of lists as orderings. All lists imply order, but what kind of order? Mathematicians distinguish lists from sets on the basis of a distinction focused on order. Formally, both lists and sets are collections, but a list also contains a mapping of its elements to an ordering, usually the natural or counting numbers. Sometimes this order is explicit. Numbers are written down one side of the list. Often the order is implicit to the spatial arrangement of the list. This formal idea of the list as a mapping is helpful since it suggests relational possibilities. Mappings occasion relations between sets, collections, group or multiplicities.  Mappings between list order and social order are manifestly highly contingent. A flight checklist differs greatly from a personal to-do list, even if they share many formal properties.  Listing practices in a given social setting, therefore, always index an engagement between the formal properties of the list and the necessarily more fluid dynamics of social order. From the perspective of social order, shopping lists, as they are co-constructed by a supermarket chain's recommender system, might be important intersectional zones for the conversion of average everydayness through data-analytic propensities. 

TBA - short paragraph summarising the social theory of list ordering

# D. Archaeology of recommendations  from 1984  to 2007

The main narrative of Patel's presentation concerned a shift from a well-established loyalty-card based data-mining model to a predictive, probabilistic, personally relevant re-writing of the shopping list in almost-realtime. The changes Patel described are increasingly widespread and common. While they are configured in Tesco-specific ways by DunnHumby (and this reflects a longer history), they are also broadly typical. Tesco is the largest supermarket chain in UK, famous amongst retailers for its  customer loyalty and targeted marketing programme known as 'Tesco Clubcard,' which started in 1991. DunnHumby -- founded by operations researchers Edwina Dunn and Clive Humby -- is said to have convinced the CEO of Tesco sometime in 1991 that a loyalty card program could change the supermarket chain's relationship to its customers.  Clive Humby's academic publications  are hard to track down, but an early paper given at the _Conference of Young Operational Researchers_ in Nottingham in 1984 suggests the direction that he, DunnHumby and later Tesco would take in constructing lists [@OKeefe_1984]. The abstract for Humby's presentation pre-figures an ongoing trajectory for data mining techniques aimed at eliciting detailed information on individual customer preferences.   

```{r humby-1984, fig.cap = 'Abstract from a Clive Humby presentation (Humby,1984)'}
include_graphics('figure/2_humby_young_org_1994.png')
```

While Tesco  succeeded in data-mining its customers using demographic segmentation,  and perhaps became the UK's biggest supermarket with the help of data-mining in the 1990s, the shopping environment  in 2017 is markedly different [@Turow_2017]. It is no longer organised around campaigns involving special offers or redemption of points for demographically segmented loyal customers (DunnHumby made heavy use of UK Census data). It can no longer rely on placement of goods in carefully chosen locations in stores. It needs or at least might want to continuously up-sell and cross-sell to customers who might hardly ever visits the supermarket itself. 

How could we characterise the shift from ClubCard data mining to online grocery markets?  If 'Tesco is the clear winner in the online grocery market, in fact it takes almost 50p of every £1 spent on food shopping on the internet' [How SEO helps Tesco to dominate the online grocery market](https://econsultancy.com/blog/64841-how-seo-helps-tesco-to-dominate-the-online-grocery-market)[@Silverwood-Cope_2014], then Tesco itself has undergone some kind of conversion? Patel described her work at DunnHumby as shifting the recommender system from a 'rules-based list' to a 'relevancy model.' The relevancy model changed how the 'Have You Forgotten' list was constructed.   This shift is a typical of broader re-organisation of prediction in which existing data analysis practices are being re-distributed and intensified in particular ways. The shift in models results in a more probabilistic structuring of lists.  The ostensible banality of the 'Have you forgotten?' recommendations betrays micrological signs of a topologically complex predictive infrastructure that intervenes in list-based social ordering to reconfigure alignments between people and things. 

This is not a drastic or abrupt event. Academic researchers first began writing about recommender systems in the mid-1990s. From the outset they highlighted a potential shift from demographic-driven market research or data mining techniques to personalized recommendations. For instance, writing in 1997 in a special section of the _Communications of the ACM_ on recommender systems, Paul Resnick and Hal Varian (at that time Dean of Information Sciences at UC Berkeley, but currently Chief Economist at Google), made much of this personalisation [@Resnick_1997]. Resnick and Varian  emphasise the need to distinguish the emerging practices from data mining: 

> In everyday life, we rely on recommendations from other people. ... Recommender systems augment this natural social process. In a typical recommender  system, people provide recommendations as inputs, which the system then aggregates and directs to appropriate recipients. In some cases the primary transformation is in the aggregation; in others the system’s value lies in its ability to make good matches between the recommenders and those seeking recommendations.[@Resnick_1997,56] 

Writing just after the advent of web-based e-Commerce, Resnick and Varian  imagined recommender systems augmenting the 'collaborative filtering' that people do when they write and read reviews of products and services (for instance, on the travel website, TripAdvisor; [@Scott_2012]). In 1997,  Resnick and Varian thought that 'people provide recommendations' and recommender systems would aggregate and rank for recipients. A slightly later review, [@Schafer_2001], diagrams an augmented 'natural social process' with a range of elements, technologies, inputs and outputs, with varying degrees of personalization. 


[BREAK HERE] 

# E. Experimenting with probabilistic conversions

## The realization of propensities

>the introduction of propensities amounts to generalizing and extending the idea of forces again  14

>they should be regarded as _inherent in a situation_ 14

The conversion of  collaborative filtering into predictive personalisation appeared throughout  Patel's presentations. Patel described a move or 'conversion'  from 'a rules-based system'  to  a 'personal relevance model' as the basis of the recommender system. Each term in that phrase -- personal, relevance and model -- has some weight in the conversion event. Again, dealing with the sometimes telegraphic style of machine learning presentations means making some assumptions. It is reasonable to assume that what Patel describes as  the 'rule-based system' refers  to the extremely well-known `apriori` algorithm, developed  by computer scientists Rakesh Agrawal and Ramakrishnan Srikanti working at IBM Research Alameda in the early 1990s [@Agrawal_1994]. A now-classic approach to 'market basket analysis,' it was listed as one of the top ten data mining algorithms in a survey conducted amongst data miners [@Wu_2008] and usually attracts a chapter in data-mining and machine learning textbooks (e.g. [@Hastie_2009]). The interest of `apriori` for our purposes is that it relies on massive datasets, but does not personalize its recommendations.

The media theorist Mark Hansen has recently suggested that 'predictive analytics are discoveries of micrological propensities that are not directly correlated with human understanding and affectivity and that do not by themselves cohere into clearly identifiable events' [@Hansen_2015a, 111-112]. Hansen's account differs from many widely shared views of big data. In the face of the so much personalization (and Patel's presentation exemplifies this), Hansen suggests a somewhat processes of impersonalization.  If  much predictive practice attempts to elicit 'micrological propensities' from data,   Hansen, drawing on the work of the philosopher of science Karl Popper,  links data to things via probabilities:

>Whatever explanatory and causal value predictive analytics of large datasets have is, I suggest, ultimately rooted in this ontological transformation whereby probabilities are understood to be expressions of the actual propensity of things [@Hansen_2015a, 120] 

Hansen theorises big data or predictive analytics as an 'ontological transformation' that deploys probabilities in an evermore closely woven and encompassing expression of animated, eventful, propensities of things. Predictive analytics links probabilities as calculations to propensities or the mutable associative agencies of things. The practical and indeed empirical  question is whether such transformations or 'conversion' in relations between probabilities and 'the propensities of things'  can be detected and articulated in the prosaic setting of shopping lists and recommender systems.[^20.1] The series of prototyping reconstructions I am about to discuss will explore the tenability of this rather radical alternative to regular narratives of personalization.

[^20.1]: I will argue that 'conversion' is a preferable term for these changes.  It highlights  re-orientations in subjects, experience, things, numbers and structures that ranges more widely than Hansen's 'ontological transformation' formulation. Not much hinges on the choice of terms, but 'conversion' happens to be the term used by Patel. 

## Apriori as conditional probabilities

> we need _a calculus of relative or conditional probabilities_ as opposed _a calculus of absolute probabilities_ 16

```{r arules-ex, cache=TRUE, fig.cap='Frequency of association betwene items in the `Grocery` dataset', message=FALSE, echo=FALSE, fig.margin=TRUE}
library(knitr)
library(arules)
library(arulesViz)
library(datasets)
data(Groceries)
itemFrequencyPlot(Groceries,topN=10,col=rainbow(10), ntype="absolute",  cex.axis = 0.55)
```

```{r arules-ex2}
options(digits=2)
rules<- apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2), appearance = list(default="rhs",lhs="whole milk"), control = list(verbose=FALSE))
rules_sorted <- sort(rules, decreasing=TRUE,by="confidence")
kable(inspect(rules_sorted[1:5]), caption='The first five association rules for the `Groceries` dataset')
```


The `apriori` algorithm finds sets of items that commonly occur together in transactions.  These commonly occurring sets are expressed as 'association rules.' For instance, using the `Groceries` dataset in the `R` package `arules,` we can readily see how Walmart *might* have discovered   the fabled association between diapers and beer.[^149.1] Figure \@ref(fig:arules-ex) shows how often common items appear. `Whole milk` appears most frequently.  The association rule-based model for the `Groceries` dataset illustrates some characteristic ordering practices of 1990s-style data-mining approaches to lists (the `Groceries` dataset  was acquired from a 'local German supermarket' [@Hahsler_2006a]). The association between items is expressed in the form of _rules_ not a model. These rules, a term derived from older decision support literature, define sets of associations between items. Table \@ref(tab:arules-ex2) shows that the first rule has a stronger association than the second. Milk and vegetables is more likely an association than milk and buns.  A rules-based recommender system should, therefore, might put them in that order in the 'Have You Forgotten' list. 

[^149.1]: One of the founding narratives of big data customer analytics, the beer-diaper association was not, according to [@Power_2002] found through data mining at all.

Although association rules and the `apriori` algorithm present social order in terms of sets of frequency-weighted associations, an `apriori`-based recommender system contains no statistical model. It also no grasp on personal relevance since the associations it defines are only between things. Put in terms of the big data conversion, the rules-based system is not predictive, or personal. The `apriori` algorithm might be seen as an attempt to grasp the excess of things in a Tesco supermarket by identifying subsets whose closure derives from the associations between things that people construct (through buying habits, by virtue of a shopping list, etc.). In association rules, personhood or experience is irrelevant. The openness of these rules -- the `apriori` algorithm can product any number of rules of diminishing strength -- points towards the propensity of things to find themselves together in shopping baskets, but cannot cannot individuate that propensity beyond demographic quantiles and categories. 

## `Apriori` meets the API 

Even if `apriori`  elicits associations between things, it struggles with the propensity of commodities to multiply. A simple illustration of the combinatorial problem faced by recommender system can be developed using the `Grocery` dataset.  If we take all the items in the `Grocery` dataset and paste them into the 'shopping list' box on the Tesco grocery website (or as I side, run them as searches on the TescoLab Product API), each of the 169 items in the dataset yields dozens and sometimes thousands of products from Tesco online.

```{r tesco-ex, echo=FALSE, cache=TRUE, fig.cap ='Tesco surplus',  fig.margin=TRUE}
    library(ggplot2)
    tesco = read.csv('data/reference_data/tesco_groceries.csv')
    total = sum(tesco$actual, na.rm=TRUE) 
    tesco = na.omit(tesco)
    tesco$actual = as.integer(tesco$actual)
    ggplot(tesco[tesco$actual>50,], aes(x=labels, y=actual, fill=labels)) +geom_bar(stat='identity') + coord_flip() + ggtitle('Tesco grocery items with more than 50 products') + theme(legend.position="none", axis.text=element_text(size=7))
```

Items in the `Groceries` dataset proliferate into a Tesco's list of branded variations. The 169 items of the `Groceries` dataset  expand into roughly `r total` Tesco items (see Figure \@ref(fig:tesco-ex)).  There is, I would suggest, a logistic propensity in things that recommender systems encounter in the ways of global supply chains. The multiple listed  in the `Grocery` dataset becomes more open in this setting through new impersonal intersections that must be bounded and ordered. The proliferation of things on the shelves of supermarket or grocery warehouse confronts produces a combinatorial problem for data miners. `r total` products (actually Patel mentioned 200,000 products) can be combined in a vast number of ways. If a typical shopping list has 20 items, then there are `r format(choose(total, 20), 2)` possible lists. Some of this vast number of possible shopping lists are highly unlikely in terms of typical purchasing patterns, but potentially valuable as recommendations. 

##  The list in its mapping to probabilities

Conditional probability; the models
[TBA - section on the role of probability; and logr] 

## Repeating sufficiently often to measure

52 weeks of data
> in many kinds of events this is not the case, and the propensities cannot be measured because the relevant situation changes and cannot be repeated 17

##  Platform Experiments that reduce interfering propensities

> experiments. ... by creating, at will, artificial conditions that either exclude, or reduce to zero, all the interfering and disturbing propensities 23

## The openness of the data -- new possibilities 

> What may happen in the future .. is, to some extent, open. There are many possibilities trying to realize themselves, but few of them have a very high propensity, given the initial conditions. 22

# F. Conclusion

In their mundane intersectional practices of ordering, recommender systems show how  predictive practices affect existing forms of social order in the world. Rather than directly positing an ontological transformation (as Hansen does), or pointing to the erosion of social order (as Turow does), I have explored some of the conversion events associated with a shift from a data-mining rule-based system to a predictive recommender system. The DunnHumby model and the Tesco 'Have You Forgotten?' recommendations present many of the traits of the conversion processes associated with big data. Rather than discontinuous changes, the conversion of the recommender system via a relevance model suggests an ongoing problematization of propensities. We have seen several types of conversion events: ongoing transformation of models and infrastructures, the experimentalisation  of recommendations, and the broader diffusion of a calculus of probabilities into a fibrous weave of propensities and conditionalities, warping over time. The predictive assemblages connect logistical ensembles to the negotiation, compromises, rituals and local orderings of everyday life.

I have been suggesting that predictive listing in the form of open-ended recommendation changes social order. It establishes a common coding between machinic and ritual repetition (as exemplified in the shopping list).  It also suggests some ways in which repetition or reiteration  can also participate in changing and emergent order. By understanding the world in terms of propensities, we have a chance  to engage with contemporary predictive processes in ways that both acknowledge their relentless and exhausting pressure to consume more and retain some chance of inhabiting the world differently. 

Rather than understanding prediction as the closed form of an ontologically open world ('the propensities of things'), the DunnHumby relevance model, in all its statistical, infrastructural, organisational and banal complexity, suggests that the predictive conversion remains constitutively incomplete. Shopping lists in all their banal yet primary orderings are fertile terrain for prediction because they are incomplete, somewhat open and mutable forms.  The constitutive incompleteness and openness of lists are very closely entangled with ongoing processes of ordering and othering, and at the same time, can accommodate predictive operations.   Lists undergoing a 'conversion' experience as they become more probabilistic, but their heterogeneous character as operations caught up in models, infrastructures, experiments, and the flow of commodities means that they can never form a closed set or dataset. The problem of 'constructing good features,' a problem that any predictive model must address, persists as the site of experiments in partly open structures.

A constitutive openness to new associations, new combinations, new groupings or actors is integral to the conversion events associated with contemporary data practice. In their account of the Netflix recommender system, Ted Hallinan and Peter Striphas make the following argument:

> These systems, and more importantly their algorithms, play a critical role in deciding which articles (or parts thereof) gain admission to the cultural realm, and in what form. Their doing so thus points in the direction of another universe of reference—a court of algorithmic appeal in which objects, ideas, and practices are heard, cross-examined, and judged independently, in part, of human beings [@Hallinan_2014, 13]

Despite the somewhat troubling reference to 'another universe,' as if Netflix or DunnHumby's recommender systems occupy a different reality, Hallinan and Striphas usefully and aptly highlight how such systems  mingle  objects, ideas and practices.

Something similar happens to shopping in the Dunnhumby relevance model. In the customer-product association matrix, in the product-product similarity matrix, in the 14,000 variables included in the logistic regression model, a 'universe of reference' takes shape. The shopping list, the commonplace inscription of normative and actual social order, takes on a complex temporal-material structure that mixes prediction, infrastructural constraints, the individual characteristics of list-makers, statistical validations, database architectures and above all the surplus sensibility associated with  circulation and consumption of commodities. Shopping lists undergoing a conversion experience as they become more probabilistic, but the idea that probabilities are the closed form of propensities does not account for the distribution of probabilities in relations between things, between people, between people and things, and between things and people.
